{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow_hub as hub\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers\n",
    "\n",
    "# from tensorflow.keras.datasets import mnist\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             multiple                  50240     \n",
      "                                                                 \n",
      " dense_5 (Dense)             multiple                  650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Layer dense_4 is not connected, no input to return.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m model  \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomplete_saved_model/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39msummary())\n\u001b[1;32m---> 11\u001b[0m base_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m \u001b[38;5;66;03m# перше\u001b[39;00m\n\u001b[0;32m     12\u001b[0m base_outputs\u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;66;03m# останні\u001b[39;00m\n\u001b[0;32m     13\u001b[0m final_output \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m10\u001b[39m)(base_outputs)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\base_layer.py:2024\u001b[0m, in \u001b[0;36minput\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Layer dense_4 is not connected, no input to return."
     ]
    }
   ],
   "source": [
    "# ================================================ #\n",
    "#                  Pretrained-Model                #\n",
    "# ================================================ #\n",
    "(x_train, y_train), (x_test, y_test) =mnist.load_data()\n",
    "x_train = x_train.reshape(-1,28*28).astype(\"float32\") /255.0\n",
    "x_test =   x_test.reshape(-1,28*28).astype(\"float32\") /255.0\n",
    "\n",
    "model  = keras.models.load_model(\"complete_saved_model/\")\n",
    "print(model.summary())\n",
    "\n",
    "base_inputs = model.layers[0].input # перше \n",
    "base_outputs= model.layers[-1].output # останні\n",
    "final_output = layers.Dense(10)(base_outputs)\n",
    "\n",
    "model = keras.Model(inputs=base_inputs, outputs=final_output)\n",
    "print(model.summary())\n",
    "# це пропустив бо не було що змінювати"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000163A28257E0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_train_function.<locals>.train_function at 0x00000163A28257E0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000163A28257E0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_train_function.<locals>.train_function at 0x00000163A28257E0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 14s 14s/step - loss: 1.9713 - accuracy: 0.2000\n",
      "Epoch 2/15\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.2358 - accuracy: 1.0000\n",
      "Epoch 3/15\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 4.1928e-04 - accuracy: 1.0000\n",
      "Epoch 4/15\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.4255e-04 - accuracy: 1.0000\n",
      "Epoch 5/15\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 8.1389e-05 - accuracy: 1.0000\n",
      "Epoch 6/15\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 6.1675e-05 - accuracy: 1.0000\n",
      "Epoch 7/15\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 6.2580e-05 - accuracy: 1.0000\n",
      "Epoch 8/15\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 7.0185e-05 - accuracy: 1.0000\n",
      "Epoch 9/15\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 8.4177e-05 - accuracy: 1.0000\n",
      "Epoch 10/15\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 9.9861e-05 - accuracy: 1.0000\n",
      "Epoch 11/15\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.1009e-04 - accuracy: 1.0000\n",
      "Epoch 12/15\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.1161e-04 - accuracy: 1.0000\n",
      "Epoch 13/15\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.0529e-04 - accuracy: 1.0000\n",
      "Epoch 14/15\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 8.9801e-05 - accuracy: 1.0000\n",
      "Epoch 15/15\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 7.3115e-05 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x163ec7cb670>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =================================================== #\n",
    "#                Pretrained Keras Model               #\n",
    "# =================================================== #\n",
    "\n",
    "x = tf.random.normal(shape=(5 ,299,299,3))\n",
    "y=  tf.constant([0,1,2,3,4])\n",
    "\n",
    "model = keras.applications.InceptionV3(include_top=True)\n",
    "# print(model.summary())\n",
    "\n",
    "base_inputs = model.layers[0].input\n",
    "base_outputs = model.layers[-2].output\n",
    "\n",
    "final_outputs = layers.Dense(5)(base_outputs)\n",
    "new_model = keras.Model(inputs=base_inputs, outputs=final_outputs)\n",
    "\n",
    "new_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "new_model.fit(x, y, epochs=15, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000163BB35BA30> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_train_function.<locals>.train_function at 0x00000163BB35BA30>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000163BB35BA30> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_train_function.<locals>.train_function at 0x00000163BB35BA30>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000163BB35BA30> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_train_function.<locals>.train_function at 0x00000163BB35BA30>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 5s 5s/step - loss: 4.9019 - accuracy: 0.2000\n",
      "Epoch 2/15\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.2455 - accuracy: 0.8000\n",
      "Epoch 3/15\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0922 - accuracy: 1.0000\n",
      "Epoch 4/15\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 5/15\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 6/15\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 7/15\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 8/15\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 9/15\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 10/15\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 9.7667e-04 - accuracy: 1.0000\n",
      "Epoch 11/15\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 7.4809e-04 - accuracy: 1.0000\n",
      "Epoch 12/15\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 6.2533e-04 - accuracy: 1.0000\n",
      "Epoch 13/15\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 5.5172e-04 - accuracy: 1.0000\n",
      "Epoch 14/15\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 5.0253e-04 - accuracy: 1.0000\n",
      "Epoch 15/15\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 4.6609e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x163bb4d0400>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ================================================= #\n",
    "#                Pretrained Hub Model               #\n",
    "# ================================================= #\n",
    "\n",
    "x = tf.random.normal(shape=(5, 299, 299, 3))\n",
    "y= tf.constant([0,1,2,3,4])\n",
    "\n",
    "url = 'https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4'\n",
    "\n",
    "base_model = hub.KerasLayer(url, input_shape=(299,299,3))\n",
    "base_model.trainable=False\n",
    "model = keras.Sequential([\n",
    "    base_model,\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64,  activation='relu'),\n",
    "    layers.Dense(5)\n",
    "])\n",
    "\n",
    "new_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "new_model.fit(x, y, epochs=15, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
